{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Frozenlake-v0 RLagent",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ydlt7e_y68H7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the Environment\n",
        "\n",
        "env = gym.make('FrozenLake-v0')"
      ],
      "metadata": {
        "id": "2JkrCnhc7BZ3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the Q Table and set it to 0\n",
        "\n",
        "action_size = env.action_space.n\n",
        "state_size = env.observation_space.n"
      ],
      "metadata": {
        "id": "LWQ3Vy0T7MLC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qtable = np.zeros((state_size, action_size))\n",
        "print(qtable)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4yTW_9K8TGJ",
        "outputId": "22d10145-eaea-413a-d5ba-e5b0c6fe1dac"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specifying HyperParameters \n",
        "\n",
        "total_episodes = 15000\n",
        "learning_rate = 0.8\n",
        "max_steps = 99\n",
        "gamma = 0.95\n",
        "\n",
        "# Exploration Paramaters\n",
        "\n",
        "epsilon = 1.0\n",
        "max_epsilon = 1.0\n",
        "min_epsilon = 0.01\n",
        "decay_rate = 0.005"
      ],
      "metadata": {
        "id": "04Pbsoet8TDU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Q-Learning algorithm\n",
        "\n",
        "rewards = []\n",
        "\n",
        "for episode in range(total_episodes):\n",
        "  state = env.reset()\n",
        "  step = 0\n",
        "  done = False\n",
        "  total_rewards = 0\n",
        "  for step in range(max_steps):\n",
        "    exp_exp_tradeoff = random.uniform(0,1)\n",
        "    if exp_exp_tradeoff > epsilon: # Do Exploitation(return the max value of Q-Table)\n",
        "      action = np.argmax(qtable[state,:])\n",
        "    else:\n",
        "      action = env.action_space.sample()\n",
        "    new_state, reward, done, info = env.step(action)\n",
        "    # Update the Q-Table after performing the action\n",
        "    qtable[state,action] = qtable[state,action] + learning_rate*(reward + gamma*np.max(qtable[new_state,:]) - qtable[state,action])\n",
        "    total_rewards += reward\n",
        "    state = new_state\n",
        "\n",
        "    if done == True:\n",
        "      break;  # End of Episode\n",
        "  # Reduce epsilon as we aldready know some part of the environment due to the exploration\n",
        "  epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
        "  rewards.append(total_rewards)\n",
        "\n",
        "print('score over time ' + str(sum(rewards)/total_episodes))\n",
        "print(qtable)\n",
        "\n",
        "\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4yEhIQd-XWo",
        "outputId": "5f6d45b9-9471-4220-edb7-9cf89008b031"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score over time 0.4703333333333333\n",
            "[[1.76177301e-01 6.27906775e-02 5.91417972e-02 3.02900208e-02]\n",
            " [9.18574741e-03 1.12605406e-02 3.07160728e-03 2.48896598e-01]\n",
            " [1.22577726e-02 1.64618421e-02 5.03164666e-03 1.31941526e-02]\n",
            " [1.24052656e-04 9.72868609e-04 5.31341266e-03 5.89078803e-02]\n",
            " [1.13109854e-01 4.59728321e-02 5.21029457e-03 3.09910041e-02]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.89907346e-04 8.90664718e-02 4.37536255e-04 7.61929233e-06]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [3.44019621e-02 3.19120475e-02 3.71351602e-02 8.90098116e-02]\n",
            " [4.55541541e-02 1.42241939e-01 3.71196766e-03 1.33870646e-02]\n",
            " [6.48439636e-01 1.77995676e-03 2.22200580e-03 1.13172775e-03]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.94880183e-02 1.20869027e-01 7.62731619e-01 1.28183922e-01]\n",
            " [3.90864298e-02 7.28525458e-02 6.03442765e-02 9.93103660e-01]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()\n",
        "\n",
        "for episode in range(10):\n",
        "  state = env.reset()\n",
        "  step = 0\n",
        "  done = False\n",
        "  print('EPISODE ', episode)\n",
        "  for step in range(max_steps):\n",
        "    action = np.argmax(qtable[state,:])\n",
        "    new_state, reward , done , info = env.step(action)\n",
        "    if done:\n",
        "      env.render()\n",
        "      print('Number of steps ',step)\n",
        "      break\n",
        "    state = new_state\n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekSyLYjuHbQK",
        "outputId": "fdfe6d95-fa76-4e0d-8a85-72733113f7a5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPISODE  0\n",
            "  (Up)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "Number of steps  85\n",
            "EPISODE  1\n",
            "  (Up)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "Number of steps  21\n",
            "EPISODE  2\n",
            "  (Down)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "Number of steps  63\n",
            "EPISODE  3\n",
            "  (Up)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "Number of steps  27\n",
            "EPISODE  4\n",
            "  (Up)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "Number of steps  57\n",
            "EPISODE  5\n",
            "  (Up)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "Number of steps  73\n",
            "EPISODE  6\n",
            "  (Up)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "Number of steps  22\n",
            "EPISODE  7\n",
            "  (Up)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "Number of steps  36\n",
            "EPISODE  8\n",
            "  (Up)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "Number of steps  34\n",
            "EPISODE  9\n"
          ]
        }
      ]
    }
  ]
}